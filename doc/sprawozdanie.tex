\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{polski}
\usepackage{tikz}
\usepackage{siunitx,booktabs}
\sisetup{
    table-auto-round
}

\title{Numeryszne metody przybliżania lokalnych ekstremum - sprawozdanie}
\author{Bartosz Zasieczny}

\begin{document}

\maketitle
\tableofcontents

\section{Zadanie}
Korzystając z omówionych na wykładzie iteracyjnych metod aproksymacji pierwiasków, zaproponować sposób wyznaczania \textbf{\emph{ekstremum lokalnego}} funkcji \( f \in C^1[a,b] \). Wykonać eksperymenty m. in. dla:
\begin{enumerate}
  \setcounter{enumi}{-1}
  \item \( f(x) = sin(2 \pi x) \), \( x \in [0,1] \); 
  \item \( f(x) = e^{-x^2} \), \( x \in [-1, 1] \); 
  \item\( f(x) = \frac {x} {1+x^2} \), \( x \in [0,10] \); 
  \item\( f(x) = x^2 + x - 1 \), \( x \in [-1,2] \).
\end{enumerate}

\section{Aparat matematyczny}
  W poszukiwaniu ekstremów funkcji będziemy używać poniższych metod. Niektóre z nich pozwalają na znalezienie ekstremum wprost, inne będą skupiać się na poszukiwaniu miejsca zerowego pierwszej pochodnej funkcji tam gdzie to możliwe.
  \subsection{Metoda Newtona}
  \textbf{Metoda Newtona} polega na iteracyjnym wyznaczaniu kolejnych przybliżeń pierwiastka \( f(x) \) poprzez: 
  \begin{itemize}
    \item znalezienie stycznej do jej wykresu w punkcie \(x_i\) (zaczynając od punktu startowego \(x_0\)); 
    \item biorąc wartosć dziedziny w punkcie przecięcia stycznej z osią \(X\) za \(i+1\)-sze przyblizenie pierwiastka (czyli \( x_{i+1} \)).
  \end{itemize}
  Kroki powtarzamy aż do otrzymania wymaganej precyzji.
  Kolejne przybliżenia \( x_{i+1} \) wyznaczamy za pomocą wzoru:
  $$ x_{i+1} = x_i - \frac {f(x_i)} {f'(x_i)} $$
  \subsubsection{Uwagi}
  
  \begin{itemize}
    \item Charakterystyka tego zadania uniemożliwia użycie samej metody Newtona - dla pewnych danych może ona wskazać przybliżenia pierwiastka \( f(x) \) spoza pożądanego przedziału. Problemem też jest dobór odpowiedniego punktu startowego - dlatego w przypadku tego zadania należy stosować tę metodę tylko po wstępnym przybliżania pierwiastka funkcji przez inne metody iteracyjne.
    \item W przypadku tego zadania każda badana funkcja musi posiadać co najmniej dwie pochodne.
  \end{itemize}
  
  \subsection{Metoda bisekcji}
  Dla funkcji \( f(x) \) ciągłej w przedziale \( [a,b] \) i przyjmującej na jego końcach wartości o różnych znakach (\( f(a) f(b) < 0 \)) należy wykonać następujące kroki:
  \begin{enumerate}
    \item sprawdzić, czy srodek przedziału jest pierwiastkiem funkcji (sprawdzić czy \( f(x) \) dla wartości dziedziny \(x_0 = \frac {a + b} {2} \) ma wartość \(f(x_0) = 0 \);
    \item jeśli tak, to zakończyć algorytm i zwrócić \(x_0\);
    \item w p. p. sprawdzić który z przedziałów (\( [a, x_0] \) czy \( [x_0, b] \)) spełnia własnosć \( f(a')f(b') < 0 \) i zastosować do niego pierwszy krok algorytmu.
  \end{enumerate}
  
  \subsection{Metoda \emph{złotego podziału}}
    Ta metoda w odróżnieniu od poprzednich pozwala szukać lokalnego ektremum wprost, bez konieczności odwoływania się do pochodnych danej funkcji i poszukwiania ich zer. Żeby funkcja \( f(x) \) mogła zostać zbadana za pomocą tej metody, musi być ona w przedziale \( [a,b] \), w którym poszukujemy ekstremum, \textbf{\emph{unimodalna}} -- tzn. ciągła i posiadać w tym przedziale dokładnie jedno ekstremum.
    \subsubsection{Algorytm}
    Pierwszy krok algorytmu:
    $$ \left\{\begin{array}{l}
    x_L^{(0)} := b^{(0)} - (b^{(0)}-a^{(0)})k \\ \\
    x_R^{(0)} := a^{(0)} + (b^{(0)}-a^{(0)})k
    \end{array}\right. $$
    
    Następnie iterujemy po przypadkach, aż do uzyskania zadowalającej precyzji:
    \begin{itemize}
      \item \( f(x_L^{(i)}) > f(x_R^{(i)}) \Rightarrow \left\{\begin{array}{l}
        a^{(i+1)} := x_L^{(i)} \\
        b^{(i+1)} := b^{(i)} \\
        x_L^{(i+1)} := x_R^{(i)} \\
        x_R^{(i+1)} := a^{(i+1)} + (b^{(i+1)}-a^{(i+1)})k
        \end{array}\right. \)
      \item \( f(x_L^{(i)}) < f(x_R^{(i)}) \Rightarrow \left\{\begin{array}{l}
        a^{(i+1)} := a^{(i)} \\
        b^{(i+1)} := x_R^{(i)} \\
        x_L^{(i+1)} := b^{(i+1)} - (b^{(i+1)}-a^{(i+1)})k \\
        x_R^{(i+1)} := x_L^{(i)}
        \end{array}\right. \)
    \end{itemize}
    Po zakończeniu iteracji, środek przedziału $[a,b]$ jest brany jako przybliżenie lokalnego ekstremum funkcji.
  \section{Badanie funkcji}
    Do wykonywania obliczeń używana jest arytmetyka w standardzie IEEE 754 \emph{double}.
    \subsection{Funkcja 0.}
      Wzory i wykresy funkcji i pochodnych w podanym przedziale: \\ 
      \begin{center}
      \begin{tikzpicture}[x=8cm,y=1.6cm]

        \def\xmin{0}
        \def\xmax{1}
        \def\ymin{-1}
        \def\ymax{1}

        \draw[style=help lines, ystep=0.2, xstep=0.1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {0, 0.5 ,..., 1}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {-1,-0.5 ,...,1}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=red, domain=\xmin:\xmax] plot[id=f]
          function{sin(2*pi*x)} node [right] {$f(x)$};
  
      \end{tikzpicture}
      \end{center}
      $$ f(x) = sin(2 \pi x)  \textrm{,} \; x \in [0,1] $$
      \begin{center}
      \begin{tikzpicture}[x=8cm,y=0.3cm]

        \def\xmin{0}
        \def\xmax{1}
        \def\ymin{-7}
        \def\ymax{7}

        \draw[style=help lines, ystep=1, xstep=0.1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {0, 0.5 ,..., 1}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {-7,-6 ,...,7}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=red, domain=\xmin:\xmax] plot[id=fd]
          function{2 * pi * cos(2*pi*x)} node [right] {$f^{(1)}(x)$};
  
      \end{tikzpicture} 
      \end{center}
      $$ f^{(1)}(x) = 2 \pi \cdot cos(2 \pi x) $$
      \begin{center}
      \begin{tikzpicture}[x=8cm,y=0.04cm]

        \def\xmin{0}
        \def\xmax{1}
        \def\ymin{-48}
        \def\ymax{48}

        \draw[style=help lines, ystep=16, xstep=0.1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {0, 0.5 ,..., 1}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {-48,-32 ,...,48}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=red, domain=\xmin:\xmax] plot[id=fd2]
          function{-4 * pi**2 * sin(2*pi*x)} node [right] {$f^{(2)}(x)$};
  
      \end{tikzpicture} 
      \end{center}
      $$ f^{(2)}(x) = -4 \pi^2 \cdot sin(2 \pi x) $$
      
      Z wykresów można wywnioskować, że w tym przedziale funkcja $ f \in C^2 $. Na wykresie $ f $ można zauważyć, że w przedziale $[0,1]$ ma ona 2 ekstrema -- jedno minimum, jedno maksimum. Sugeruje to możliwość użycia metody \emph{złotego podziału}. Możemy natomiast użyć metody bisekcji, ew. łącząc ją z metodą Newtona (trzeba jednak uważać, gdyż na końcach przedziału $f^{(2)}(0) = 0$ i $f^{(2)}(1) = 0$ -- nie mozemy użyć $ x = 0 $ i $ x = 1 $ jako punktów startowych tej metody).
      
      \subsubsection{Metoda \emph{złotego podziału}}
      Polecenie: \texttt{./main -m golden\_section -f 0 -s 0 1 -i 50 -error 10e-8} \\
      \begin{center}
      \begin{tabular}{S[table-format=1.0]S[table-format=-1.9]S[table-format=-1.15,table-auto-round=false]}
        \toprule
        {$i$}                & {$x_i$}               & {$f(x_i)$}            \\ \midrule
          0 & 0.69098300562505254874 & -0.93203242381322759513 \\
          1 & 0.80901699437494745126 & -0.93203242381322770616 \\
          2 & 0.73606797749978958301 & -0.99617104086482766157 \\
          3 & 0.78115294937452672830 & -0.98090406160281717884 \\
          4 & 0.75328890437410611636 & -0.99978649070871195015 \\
          5 & 0.73606797749978958301 & -0.99617104086482766157 \\
          31 & 0.75000003172107387872 & -0.99999999999998012701 \\
          32 & 0.74999999251167026593 & -0.99999999999999888978 \\
          33 & 0.75000001674441429955 & -0.99999999999999444888 \\ \bottomrule
        \end{tabular}
    \end{center}
    
    Metoda \emph{złotego podziału} dla tej funkcji osiąga wymaganą precyzję (badany przedział jest mniejszy niż $10^{-8}$) dopiero po 34 iteracjach. W ten sposób znaleźliśmy przyblizenie tylko lokalnego minimum funkcji $ f(x) = -1\textrm{,}\; x = 0.75 $ i błąd przyblizenia wynosi $ |x_{33} - x| \approx 0.00000001674441429955 $. \\
    Chcąc przybliżyć minimum nalezy wykonać to samo polecenie dodając paramatr \texttt{-e max}. Lokalne maksimum funkcji znajduje się w $ x = 0.25 $ i $ f(x) = 1 $ - aby otrzymać wynik o takiej samej precyzji należy wykonać dokładnie tyle samo iteracji i błąd przybliżenia jest bardzo zbliżony. Trzeba jednak pamiętać, że dokładność przyblizeń w przypadku tej funkcji zależy nie tylko od precyzji arytmetyki, ale również od dokładności reprezentacji piczby $\pi = 3.14159265358979323846$ (reprezentacja w \texttt{cmath}). \\
    Dla tej funkcji metoda \emph{złotego podziału} daje wyniki o rządanej precyzji po dość dużej liczbie iteracji. Aby otrzymać precyzję rzędu $10^{-16}$ program musi wykonać 72 iteracje.
    
    \subsubsection{Użycie metody \emph{złotego podziału} jako wstęp do metody Newtona}
    Warto tej metody użyć jako wstęp do metody Newtona. Weźmy 6-tą iterację z powyższej tabeli ($ i = 5 $) i użyjmy jej jako punkt startowy do metody Newtona (polecenie: \texttt{./main -m newton -f 1 -d 2 -x 0.75328890437410611636 -error 10e-8}). Otrzymujemy następujące dane:
     \begin{center}
      \begin{tabular}{S[table-format=1.0]S[table-format=-1.9]S[table-format=-1.15,table-auto-round=false]}
        \toprule
        {$i$}                & {$x_i$}               & {$f^{(1)}(x_i)$}            \\ \midrule
         0 & 0.75328890437410611636 & 0.12983149947540237323 \\
         1 & 0.74999953176226419327 & -0.00001848528487583362 \\
         2 & 0.75000000000000011102 & 0.00000000000000442639 \\ \bottomrule
      \end{tabular}
    \end{center}
  Otrzymujemy w tym wypadku dość szybko (tylko 3 iteracje!) dane bardzo dokładne (błąd: $ |x_2 - x| \approx 0.00000000000000011102 $) przybliżenie, które jest znacznie lepsze od uzyskanego na drodze zasosowania samej metody \emph{złotego podziału}. 
    
  \subsubsection{Metoda bisekscji}
  Uzywając tej metody musimy podzielić przedział na dwa: $ [0, 0.5] $ i $ [0.5, 1]$. Łatwo zauważyć, że metoda bisekcji zakończy się wtedy już po pierwszej iteracji, gdyż już wtedy dokładnie w połówach przedziałów będziemy mieć zera $f^{(1)}$. Aby się o tym przekonać wystarczy wykonać następujące polecenia:
  \begin{itemize}
    \item \texttt{./main -m bisection -f 1 -s 0 0.5 } - dla przedziału $[0, 0.5]$,
    \item \texttt{./main -m bisection -f 1 -s 0.5 1 } - dla przedziału $[0.5, 1]$
  \end{itemize}
  Jak widać nie ma sensu łączenie tej metody z metodą Newtona, gdyż daje ona bardzo dokładne wyniki w czasie praktycznie stałym dla tej funkcji i tych danych wejściowych.
  
  \subsection{Funkcja 1.}
  Wzory i wykresy funkcji i pochodnych w podanym przedziale: \\ 
      \begin{center}
      \begin{tikzpicture}[x=4cm,y=3.2cm]

        \def\xmin{-1}
        \def\xmax{1}
        \def\ymin{0.25}
        \def\ymax{1.25}

        \draw[style=help lines, ystep=0.25, xstep=0.1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {-1, -0.5 ,..., 1}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {0.25 ,...,1.25}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=blue, domain=\xmin:\xmax] plot[id=g]
          function{exp(-x**2)} node [right] {$f(x)$};
  
      \end{tikzpicture}
      \end{center}
      $$ f(x) = e^{-x^2}  \textrm{,} \; x \in [-1,1] $$
      \begin{center}
      \begin{tikzpicture}[x=4cm,y=2cm]

        \def\xmin{-1}
        \def\xmax{1}
        \def\ymin{-1}
        \def\ymax{1}

        \draw[style=help lines, ystep=0.25, xstep=0.1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {-1, -0.5 ,..., 1}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {-1, -0.5 ,...,1}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=blue, domain=\xmin:\xmax] plot[id=gd]
          function{-2*exp(-x**2)*x} node [right] {$f(x)$};
  
      \end{tikzpicture}
      \end{center}
      $$ f^{(1)}(x) = -2e^{-2^x} \cdot x) $$
      \begin{center}
      \begin{tikzpicture}[x=4cm,y=1.5cm]

        \def\xmin{-1}
        \def\xmax{1}
        \def\ymin{-2.5}
        \def\ymax{1}

        \draw[style=help lines, ystep=0.5, xstep=0.1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {-1, -0.5 ,..., 1}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {-2.5, -2,...,1}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=blue, domain=\xmin:\xmax] plot[id=gd2]
          function{exp(-x**2)*(4*x**2-2)} node [right] {$f(x)$};
  
      \end{tikzpicture}
      \end{center}
      $$ f^{(2)}(x) = e^{-x^2} \cdot (4x^2 -2) $$
      
    \subsubsection{Metoda \emph{złotego podziału}}
    Funkcja $ f $ jest unimodalna w przedziale $ [-1,1] $, możemy więc wprost zastosować tę metodę (polecenie: \texttt{./main -m golden\_section -f 3 -s -1 1 -i 50 -error 10e-8}). Wyniki przezentują się następująco:
      \begin{center}
      \begin{tabular}{S[table-format=1.0]S[table-format=-1.9]S[table-format=-1.15,table-auto-round=false]}
        \toprule
        {$i$}                & {$x_i$}               & {$f(x_i)$}            \\ \midrule
          0 & 0.38196601125010509747 & 0.86424582259729920697 \\
          1 & 0.14589803375031540345 & 0.97893871671341148311 \\
          2 & -0.00000000000000005551 & 1.00000000000000000000 \\
          3 & 0.09016994374947417956 & 0.99190234532493570807 \\
          4 & 0.03444185374863295568 & 0.99881446201643198091 \\
          5 & -0.00000000000000008327 & 1.00000000000000000000 \\
          32 & -0.00000000000000008832 & 1.00000000000000000000 \\
          33 & 0.00000004846548804954 & 0.99999999999999766853 \\
          34 & 0.00000001851216909899 & 0.99999999999999966693 \\ \bottomrule
        \end{tabular}
    \end{center}
    Dla tej funkcji uzyskanie zadowalającej precyzji wyniku wymaga równie wieli iteracji. Patrząc na dane otrzymane z przybliżania ekstremum tej i poprzedniej funkcji można dojść do wniosku, że dla pewnych funkcji algorytm dość szybko zaczyna \emph{kręcić się} w okół rozwiązania, ale szerokość badanego aktualnie przedziału nie pozwala na zakończenie algorytmu przy obecnej iteracji. Tym razem błąd przybliżenia wynosi $ |x_{34} - x| = 0.00000001851216909899 $, a dokładnym ekstremum jest $ x = 0 $, $ f(x) = 1$.
    
  \subsubsection{Użycie metody \emph{złotego podziału} jako wstęp do metody Newtona}
  Jako punkt startowy weźmy $ x_2 = -0.00000000000000005551 $ (polecenie: \texttt{./main -m newton -f 4 -d 5 -x -0.00000000000000005551 -error 10e-8}).
  \begin{center}
      \begin{tabular}{S[table-format=1.0]S[table-format=-1.9]S[table-format=-1.15,table-auto-round=false]}
        \toprule
        {$i$}                & {$x_i$}               & {$f^{(1)}(x_i)$}            \\ \midrule
          0 & 0.00000000000000005551 & -0.00000000000000011102 \\
          1 & 0.00000000000000000000 & -0.00000000000000000000 \\ \bottomrule
        \end{tabular}
    \end{center}
      Jak widać w tym przypadku rozsądne wybranie przyblizenia z metody \emph{złotego podziału} pozwala bardzo szybko przybliżyć ekstremum funkcji. Trzeba jednak uważać na dobór punktu wyjściowego, ponieważ w tym wypadku możemy wybrać punkt który spowoduje, że metoda Newtona nie zakończy swojego działania. Łatwo się można o tym przekonać wybierając takie $ |x| > |x_{root}| \approx \pm 0.707106 $, $ f^{(2)}(x_{root}) = 0 $ (polecenie: \texttt{./main -m newton -f 4 -d 5 -i 100 -x 0.8}).
      
  \subsubsection{Metoda bisekcji}
  Zastosowanie metody bisekcji będzie miało podobny efekt jak przy poprzedniej funkcji. Aby się o tym przekonać nalezy wykonać polecenie: \texttt{./main -m bisection -f 4 -s -1 1}.
  
  \subsection{Funkcja 2.}
   Wzory i wykresy funkcji i pochodnych w podanym przedziale:  
      \begin{center}
      \begin{tikzpicture}[x=0.8cm,y=4cm]

        \def\xmin{0}
        \def\xmax{10}
        \def\ymin{0}
        \def\ymax{0.6}

        \draw[style=help lines, ystep=0.1, xstep=1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {0, 2 ,..., 10}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {0, 0.3 ,...,0.6}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=green, domain=\xmin:\xmax] plot[smooth,id=h]
          function{x/(1+x**2)} node [right] {$f(x)$};
  
      \end{tikzpicture}
      \end{center}
      $$ f(x) = \frac {x} {1 + x^2}  \textrm{,} \; x \in [0,10] $$
      \begin{center}
      \begin{tikzpicture}[x=0.8cm,y=2cm]

        \def\xmin{0}
        \def\xmax{10}
        \def\ymin{-0.5}
        \def\ymax{1.25}

        \draw[style=help lines, ystep=0.25, xstep=1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {0, 2 ,..., 10}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {-0.5, 0 ,...,1.25}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=green, domain=\xmin:\xmax] plot[smooth,id=hd]
          function{(1-x**2)/(1+x**2)**2} node [right] {$f(x)$};
  
      \end{tikzpicture}
      \end{center}
      $$ f^{(1)}(x) = \frac{1-x^2}{(1+x^2)^2} $$
      \begin{center}
      \begin{tikzpicture}[x=0.8cm,y=1cm]

        \def\xmin{0}
        \def\xmax{10}
        \def\ymin{-2}
        \def\ymax{2}

        \draw[style=help lines, ystep=0.5, xstep=1] (\xmin,\ymin) grid
        (\xmax,\ymax);

        \draw[->] (\xmin,\ymin) -- (\xmax,\ymin) node[right] {$x$};
        \draw[->] (\xmin,\ymin) -- (\xmin,\ymax) node[above] {$y$};

        \foreach \x in {0, 2 ,..., 10}
          \node at (\x, \ymin) [below] {\x};
        \foreach \y in {-2, -1.5 ,...,2}
          \node at (\xmin,\y) [left] {\y};

         \draw[color=green, domain=\xmin:\xmax] plot[smooth,id=hdd]
          function{2*x*(x**2-3)/(1+x**2)**3} node [right] {$f(x)$};
  
      \end{tikzpicture}
      \end{center}
      $$ f^{(2)}(x) = \frac{2x(x^2 - 3)}{(1+x^2)^3} $$
      
      \subsubsection{Metoda \emph{złotego podziału}}
      Zastosowanie tej metody dla tej funkcji potwierdza jej właściwości - szybko zbiega ku prawidłowemu rozwiązaniu, jednak algorytm się nie zatrzymuje gdyż aktualnie badany przedział jest za duży. (polecenie: \texttt{./main -m golden\_section -f 6 -s 0 10 -i 50 -error 10e-8 -e max}).
      \begin{center}
      \begin{tabular}{S[table-format=1.0]S[table-format=-1.9]S[table-format=-1.15,table-auto-round=false]}
        \toprule
        {$i$}                & {$x_i$}               & {$f(x_i)$}            \\ \midrule
          0 & 3.09016994374947451263 & 0.29293069691510170705 \\
          1 & 1.90983005625052615351 & 0.41094142153556473263 \\
          2 & 1.18033988749894880321 & 0.49320523891726081311 \\
          3 & 0.72949016875157757234 & 0.47612006438087856042 \\
          4 & 1.00813061875578369175 & 0.49998360708603867275 \\
          36 & 1.00000003098496703657 & 0.49999999999999977796 \\
          37 & 0.99999999562986996438 & 0.50000000000000000000 \\
          38 & 1.00000001748052169681 & 0.49999999999999988898 \\ \bottomrule
        \end{tabular}
    \end{center}
    
    
    \subsubsection{Użycie metody \emph{złotego podziału} jako wstęp do metody Newtona}
    Jako punkt wyjściowy do metody Newtona weźmiemy $ x_4 = 1.00813061875578369175 $ (polecenie: \texttt{./main -m newton -f 7 -d 8 -x 1.00813061875578369175 -error 10e-8}).
    \begin{center}
      \begin{tabular}{S[table-format=1.0]S[table-format=-1.9]S[table-format=-1.15,table-auto-round=false]}
        \toprule
        {$i$}                & {$x_i$}               & {$f^{(1)}(x_i)$}            \\ \midrule
          0 & 1.00813061875578369175 & -0.00401599788892920313 \\
          1 & 0.99989948255975735769 & 0.00005026629844595792 \\
          2 & 0.99999998484690499900 & 0.00000000757654767460 \\ \bottomrule
        \end{tabular}
    \end{center} 
    
    \subsubsection{Metoda bisekcji}
    Metoda bisekcji prezentuje następujące wyniki (polecenie: \texttt{./main -m bisection -f 7 -s 0 10 -error 10e-8 -i 30}):
     \begin{center}
      \begin{tabular}{S[table-format=1.0]S[table-format=-1.9]S[table-format=-1.15,table-auto-round=false]}
        \toprule
        {$i$}                & {$x_i$}               & {$f(x_i)$}            \\ \midrule
          0 & 5.00000000000000000000 & -0.03550295857988165771 \\
          1 & 2.50000000000000000000 & -0.09988109393579072681 \\
          2 & 1.25000000000000000000 & -0.08566329565734681628 \\
          3 & 0.62500000000000000000 & 0.31511172831713168963 \\
          4 & 0.93750000000000000000 & 0.03430137317871205516 \\
          5 & 1.09375000000000000000 & -0.04069275589308898877 \\
          6 & 1.01562500000000000000 & -0.00763130153694647519 \\
          22 & 1.00000023841857910156 & -0.00000011920924691822 \\
          23 & 0.99999964237213134766 & 0.00000017881403024946 \\
          24 & 0.99999994039535522461 & 0.00000002980232505223 \\ \bottomrule
        \end{tabular}
    \end{center}
    Metoda bisekcji szybciej niż metoda \emph{złotego podziału} kończy swoje działania, zwracając satysfakcjonujący wynik, niemniej ciąg zwracanych przyblizeń zbiega wolniej ku rozwiązaniu, dlatego też połączenie tej metody z metodą Newtona nie da szybciej dobrego rowiązania - dlatego pominiemy ten przypadek, gdyż jest mało interesujący.
    
     
  \section{Kompilacja i obsługa programu}
    \subsection{Wymagania}
    Aby skompilować program należy spełnić następujące wymagania dotyczące oprogramowania:
    \begin{itemize}
      \item kompilator $ G\!+\!+ $ w wersji 4.7 lub późniejszej - kompilator musi obsługiwać standard $ C^{++}11 $,
      \item obecność narzędzia GNU Make
    \end{itemize}
    Powyższe wymagania powinny być automatycznie spełnione w każdej aktualnej dystrybucji GNU/Linux.
    
    \subsection{Kompilacja}
    Należy przejść do katalogu \texttt{prog} i wykonać polecenie \texttt{make} - kompilacja wykona się automatycznie. W pliku \texttt{Makefile} podane są polecenia, które należy wykonać aby skompilować program ręcznie.
    
    \subsection{Obsługa programu}
    Program uruchamiamy za pomoca pliku \texttt{main}, po jego nazwie podając ciąg bedący kombinacją ponizszych parametrów:
    \begin{itemize}
      \item \texttt{-f <nr\_funkcji>} -- za pomocą tego argumentu wybieramy jedną z dostępnych funkcji - liczba przyporzadkowana funkcji to jej liczba porządkowa z treści zadania \( \cdot 3 \), dodanie 1 to pierwsza pochodna, dodanie 2 to druga pochodna,
      \item \texttt{-d <nr\_funkcji>} -- podobnie jak powyżej, tyle, że podajemy liczbę pochodnej,
      \item \texttt{-m <metoda>} -- wybór jednej z metod:
        \begin{itemize}
          \item \texttt{newton} -- metoda newtona (obowiązkowe parametry wywołania to \texttt{-f -d -x})
          \item \texttt{regula\_falsi} -- \emph{regula falsi} (obowiązkowe parametry to \texttt{-f -s})
          \item \texttt{bisection} -- bisekcja (obowiązkowe parametry to \texttt{-f -s})
          \item \texttt{golden\_section} -- metoda \emph{złotego podziału} (obowiązkowe parametry to \texttt{-f -s})
          \item \texttt{plot} -- "wykres" funkcji (punkty) (obowiązkowe parametry to \texttt{-f -s -step})
        \end{itemize}
      \item \texttt{-p <n>} -- wypisz wyniki z precyzją $n$ cyfr po przecinku (domyślnie 20),
      \item \texttt{-s <a> <b>} -- określ badany przedział od $a$ do $b$,
      \item \texttt{-x <y>} -- $y$ jako punkt startowy,
      \item \texttt{-e (min|max)} -- określ czy szukać lokalnego mininum czy maximum w przedziale (działa tylko z \texttt{-m golden\_section}, domyślnie \texttt{min}),
      \item \texttt{-error <e>} -- określ tolerancję błędu (domyślnie $ 10^{-10} $),
      \item \texttt{-step <s>} -- wielkość kroku przy obliczaniu punktów wykresu (działa tylko z \texttt{-m plot}, domyślnie 0.1),
      \item \texttt{-i <i>} -- ilość iteracji (domyślnie 20),
      
    \end{itemize}
    
    Przykład: szukamy lokalnego minimum dla pierwszej funkcji z zadania, w podanym przedziale, za pomocą metody \emph{złotego podziału}, z tolerancją błędu na poziomie $10^{-12}$, maksymalnie 30 iteracjami i precyzją 25 liczb po przecinku.
    \begin{center}
      \texttt{./main -f 0 -s 0 1 -m golden\_section -e 10e-12 -i 30 -p 25}
    \end{center}    
\end{document}
